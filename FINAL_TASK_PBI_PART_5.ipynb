{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yj2V5rPGPNGx",
        "outputId": "f256dfef-8c38-4cfd-8cac-2b8825fa15fe"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "üì¶ Loading saved model package...\n",
            "‚úÖ Loaded Hyperparameter Tuned model with AUC: 0.7374\n",
            "üìÇ Loading application_test.csv...\n",
            "üîß Preprocessing new data...\n",
            "‚ö†Ô∏è  Adding missing features: 85\n",
            "‚ö†Ô∏è  Removing extra features: 76\n",
            "üî§ Encoding categorical features...\n",
            "   Processing: OCCUPATION_TYPE\n",
            "      ‚úÖ Successfully encoded\n",
            "   Processing: ORGANIZATION_TYPE\n",
            "      ‚ö†Ô∏è  Found 7 unknown categories\n",
            "      Examples: ['Industry: type 8', 'Industry: type 6', 'Trade: type 4']\n",
            "      ‚úÖ Successfully encoded\n",
            "   Processing: AGE_GROUP\n",
            "      ‚ö†Ô∏è  Found 1 unknown categories\n",
            "      Examples: ['0']\n",
            "      ‚ö†Ô∏è  'Unknown' not in training classes for AGE_GROUP\n",
            "      Training classes: ['Adult', 'Middle', 'Senior', 'Elder', 'Young']\n",
            "      ‚Üí Mapping unknown values to: 'Adult'\n",
            "      ‚úÖ Successfully encoded\n",
            "   Processing: INCOME_CATEGORY\n",
            "      ‚ö†Ô∏è  Found 1 unknown categories\n",
            "      Examples: ['0']\n",
            "      ‚ö†Ô∏è  'Unknown' not in training classes for INCOME_CATEGORY\n",
            "      Training classes: ['High', 'Medium', 'Very_High', 'Low']\n",
            "      ‚Üí Mapping unknown values to: 'High'\n",
            "      ‚úÖ Successfully encoded\n",
            "‚úÖ Categorical encoding completed\n",
            "üîß Imputing missing values...\n",
            "‚öñÔ∏è Scaling features...\n",
            "‚úÖ Preprocessing completed. Data shape: (48744, 130)\n",
            "\n",
            "üîç Preprocessing Verification:\n",
            "Final data shape: (48744, 130)\n",
            "Any NaN values: 0\n",
            "Data type: float64\n",
            "\n",
            "üîÆ Making predictions...\n",
            "üìä Creating submission file...\n",
            "‚úÖ Predictions saved! Shape: (48744, 3)\n",
            "\n",
            "üìà Prediction Summary:\n",
            "Total predictions: 48744\n",
            "Predicted defaults (1): 241 (0.49%)\n",
            "Predicted no defaults (0): 48503 (99.51%)\n",
            "Average probability: 0.3283\n",
            "Probability range: 0.0000 - 1.0000\n",
            "\n",
            "üéâ All done! Check 'predictions_test.csv' for results.\n"
          ]
        }
      ],
      "source": [
        "# Import libraries\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import joblib\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "\n",
        "# Load the saved model package\n",
        "print(\"üì¶ Loading saved model package...\")\n",
        "model_package = joblib.load('home_credit_improved_model.pkl')\n",
        "\n",
        "model = model_package['model']\n",
        "scaler = model_package['scaler']\n",
        "label_encoders = model_package['label_encoders']\n",
        "feature_names = model_package['feature_names']\n",
        "train_median = model_package['train_median']\n",
        "threshold = model_package['threshold']\n",
        "\n",
        "print(f\"‚úÖ Loaded {model_package['method_used']} model with AUC: {model_package['performance_metrics']['auc']:.4f}\")\n",
        "\n",
        "# Load new data\n",
        "print(\"üìÇ Loading application_test.csv...\")\n",
        "new_data = pd.read_csv('application_test.csv')\n",
        "original_ids = new_data['SK_ID_CURR'].copy()\n",
        "\n",
        "# Pastikan hanya menggunakan feature yang sama dengan training\n",
        "print(\"üîß Preprocessing new data...\")\n",
        "missing_features = set(feature_names) - set(new_data.columns)\n",
        "extra_features = set(new_data.columns) - set(feature_names)\n",
        "\n",
        "if missing_features:\n",
        "    print(f\"‚ö†Ô∏è  Adding missing features: {len(missing_features)}\")\n",
        "    for feature in missing_features:\n",
        "        new_data[feature] = 0\n",
        "\n",
        "if extra_features:\n",
        "    print(f\"‚ö†Ô∏è  Removing extra features: {len(extra_features)}\")\n",
        "    new_data = new_data[feature_names]\n",
        "else:\n",
        "    new_data = new_data[feature_names]\n",
        "\n",
        "# SOLUSI PERBAIKAN: Robust Categorical Encoding\n",
        "print(\"üî§ Encoding categorical features...\")\n",
        "\n",
        "def robust_label_encode(series, label_encoder, column_name):\n",
        "    \"\"\"\n",
        "    Robust label encoding yang handle unknown categories dengan baik\n",
        "    \"\"\"\n",
        "    print(f\"   Processing: {column_name}\")\n",
        "\n",
        "    # Step 1: Handle missing values\n",
        "    series_clean = series.fillna('Unknown')\n",
        "\n",
        "    # Step 2: Convert to string dan strip whitespace\n",
        "    series_clean = series_clean.astype(str).str.strip()\n",
        "\n",
        "    # Step 3: Get training categories\n",
        "    train_categories = set([str(x).strip() for x in label_encoder.classes_])\n",
        "    test_categories = set(series_clean.unique())\n",
        "\n",
        "    # Step 4: Identify unknown categories\n",
        "    unknown_categories = test_categories - train_categories\n",
        "\n",
        "    if unknown_categories:\n",
        "        print(f\"      ‚ö†Ô∏è  Found {len(unknown_categories)} unknown categories\")\n",
        "        print(f\"      Examples: {list(unknown_categories)[:3]}\")\n",
        "\n",
        "    # Step 5: PERBAIKAN - Cek apakah 'Unknown' ada di training classes\n",
        "    if 'Unknown' not in train_categories:\n",
        "        print(f\"      ‚ö†Ô∏è  'Unknown' not in training classes for {column_name}\")\n",
        "        print(f\"      Training classes: {list(train_categories)}\")\n",
        "\n",
        "        # Pilihan 1: Map ke kategori yang paling umum di training\n",
        "        most_common_class = label_encoder.classes_[0]  # Ambil class pertama sebagai default\n",
        "        print(f\"      ‚Üí Mapping unknown values to: '{most_common_class}'\")\n",
        "\n",
        "        # Map semua unknown categories ke most common class\n",
        "        series_encoded = series_clean.apply(\n",
        "            lambda x: most_common_class if x in unknown_categories else x\n",
        "        )\n",
        "\n",
        "    else:\n",
        "        # Jika 'Unknown' ada di training, map ke 'Unknown'\n",
        "        series_encoded = series_clean.apply(\n",
        "            lambda x: 'Unknown' if x in unknown_categories else x\n",
        "        )\n",
        "\n",
        "    # Step 6: Transform dengan encoder\n",
        "    try:\n",
        "        result = label_encoder.transform(series_encoded)\n",
        "        print(f\"      ‚úÖ Successfully encoded\")\n",
        "        return result\n",
        "\n",
        "    except ValueError as e:\n",
        "        print(f\"      ‚ùå Still failed: {e}\")\n",
        "\n",
        "        # FALLBACK TERAKHIR: Manual encoding berdasarkan training classes\n",
        "        print(f\"      üîß Using fallback: map to most frequent training class\")\n",
        "\n",
        "        # Buat mapping manual ke class pertama (biasanya most frequent)\n",
        "        fallback_class = label_encoder.classes_[0]\n",
        "        fallback_encoded = label_encoder.transform([fallback_class])[0]\n",
        "\n",
        "        # Map semua ke fallback class\n",
        "        result = np.full(len(series_encoded), fallback_encoded, dtype=int)\n",
        "        print(f\"      ‚Üí All values mapped to '{fallback_class}' (encoded: {fallback_encoded})\")\n",
        "        return result\n",
        "\n",
        "# Apply robust encoding untuk semua categorical features\n",
        "for col, le in label_encoders.items():\n",
        "    if col in new_data.columns:\n",
        "        new_data[col] = robust_label_encode(new_data[col], le, col)\n",
        "\n",
        "print(\"‚úÖ Categorical encoding completed\")\n",
        "\n",
        "# Handle missing values dengan median dari TRAINING set\n",
        "print(\"üîß Imputing missing values...\")\n",
        "new_data = new_data.fillna(train_median)\n",
        "\n",
        "# Pastikan urutan kolom sama dengan training\n",
        "new_data = new_data[feature_names]\n",
        "\n",
        "# Scale features dengan scaler dari training\n",
        "print(\"‚öñÔ∏è Scaling features...\")\n",
        "new_data_scaled = scaler.transform(new_data)\n",
        "\n",
        "print(f\"‚úÖ Preprocessing completed. Data shape: {new_data_scaled.shape}\")\n",
        "\n",
        "# Verifikasi hasil preprocessing\n",
        "print(\"\\nüîç Preprocessing Verification:\")\n",
        "print(f\"Final data shape: {new_data_scaled.shape}\")\n",
        "print(f\"Any NaN values: {np.isnan(new_data_scaled).sum()}\")\n",
        "print(f\"Data type: {new_data_scaled.dtype}\")\n",
        "\n",
        "# Lanjutkan dengan prediksi\n",
        "print(\"\\nüîÆ Making predictions...\")\n",
        "predictions_proba = model.predict_proba(new_data_scaled)[:, 1]\n",
        "predictions_binary = (predictions_proba >= threshold).astype(int)\n",
        "\n",
        "# Buat hasil prediksi\n",
        "print(\"üìä Creating submission file...\")\n",
        "results_df = pd.DataFrame({\n",
        "    'SK_ID_CURR': original_ids,\n",
        "    'TARGET': predictions_binary,\n",
        "    'PREDICTION_PROBABILITY': predictions_proba\n",
        "})\n",
        "\n",
        "# Simpan hasil\n",
        "results_df.to_csv('predictions_test.csv', index=False)\n",
        "print(f\"‚úÖ Predictions saved! Shape: {results_df.shape}\")\n",
        "\n",
        "# Tampilkan ringkasan prediksi\n",
        "print(f\"\\nüìà Prediction Summary:\")\n",
        "print(f\"Total predictions: {len(results_df)}\")\n",
        "print(f\"Predicted defaults (1): {(predictions_binary == 1).sum()} ({(predictions_binary == 1).mean()*100:.2f}%)\")\n",
        "print(f\"Predicted no defaults (0): {(predictions_binary == 0).sum()} ({(predictions_binary == 0).mean()*100:.2f}%)\")\n",
        "print(f\"Average probability: {predictions_proba.mean():.4f}\")\n",
        "print(f\"Probability range: {predictions_proba.min():.4f} - {predictions_proba.max():.4f}\")\n",
        "\n",
        "print(\"\\nüéâ All done! Check 'predictions_test.csv' for results.\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Make predictions\n",
        "print(\"üéØ Making predictions...\")\n",
        "predictions_proba = model.predict_proba(new_data_scaled)[:, 1]\n",
        "predictions_binary = (predictions_proba >= threshold).astype(int)\n",
        "\n",
        "# Create submission dataframe\n",
        "results_df = pd.DataFrame({\n",
        "    'SK_ID_CURR': original_ids,\n",
        "    'TARGET_PROBA': predictions_proba,\n",
        "    'TARGET_PREDICTION': predictions_binary\n",
        "})\n",
        "\n",
        "# Save results\n",
        "output_file = 'final_predictions.csv'\n",
        "results_df.to_csv(output_file, index=False)\n",
        "print(f\"‚úÖ Predictions saved to {output_file}\")\n",
        "print(f\"üìä Prediction distribution:\")\n",
        "print(f\"   - Default predictions (1): {sum(predictions_binary)}\")\n",
        "print(f\"   - Non-default predictions (0): {len(predictions_binary) - sum(predictions_binary)}\")\n",
        "print(f\"   - Default rate: {sum(predictions_binary)/len(predictions_binary)*100:.2f}%\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IkPp54VZZ5kd",
        "outputId": "58cda535-e321-47d3-e471-bdb0120fe221"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "üéØ Making predictions...\n",
            "‚úÖ Predictions saved to final_predictions.csv\n",
            "üìä Prediction distribution:\n",
            "   - Default predictions (1): 241\n",
            "   - Non-default predictions (0): 48503\n",
            "   - Default rate: 0.49%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Analisis tambahan\n",
        "print(\"\\nüìà Prediction Analysis:\")\n",
        "print(f\"   - Min probability: {predictions_proba.min():.4f}\")\n",
        "print(f\"   - Max probability: {predictions_proba.max():.4f}\")\n",
        "print(f\"   - Mean probability: {predictions_proba.mean():.4f}\")\n",
        "\n",
        "# Simpan hasil dengan berbagai threshold untuk analisis bisnis\n",
        "for thresh in [0.3, 0.5, 0.7]:\n",
        "    binary_preds = (predictions_proba >= thresh).astype(int)\n",
        "    default_rate = sum(binary_preds)/len(binary_preds)\n",
        "    print(f\"   - Default rate at threshold {thresh}: {default_rate*100:.2f}%\")\n",
        "\n",
        "# Rekomendasi untuk tim bisnis\n",
        "print(\"\\nüí° Business Recommendations:\")\n",
        "print(\"1. Prioritasi applicant dengan probability > 0.7 untuk review manual\")\n",
        "print(\"2. Applicant dengan probability < 0.3 dapat diapprove secara otomatis\")\n",
        "print(\"3. Buat segmentasi risk-based pricing berdasarkan probability score\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yM2Xk1zzZ-Fw",
        "outputId": "668a0d4e-38b0-41f4-b496-68c0935a507e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "üìà Prediction Analysis:\n",
            "   - Min probability: 0.0000\n",
            "   - Max probability: 1.0000\n",
            "   - Mean probability: 0.3283\n",
            "   - Default rate at threshold 0.3: 56.02%\n",
            "   - Default rate at threshold 0.5: 6.26%\n",
            "   - Default rate at threshold 0.7: 0.48%\n",
            "\n",
            "üí° Business Recommendations:\n",
            "1. Prioritasi applicant dengan probability > 0.7 untuk review manual\n",
            "2. Applicant dengan probability < 0.3 dapat diapprove secara otomatis\n",
            "3. Buat segmentasi risk-based pricing berdasarkan probability score\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Quality check\n",
        "print(\"\\nüîç Quality Check:\")\n",
        "print(f\"   - Expected features: {len(feature_names)}\")\n",
        "print(f\"   - Features in new data: {new_data.shape[1]}\")\n",
        "print(f\"   - Missing values after imputation: {pd.DataFrame(new_data).isnull().sum().sum()}\")\n",
        "print(f\"   - Data shape consistency: {new_data_scaled.shape[1] == model.n_features_in_}\")\n",
        "\n",
        "# Sample predictions\n",
        "print(\"\\nüëÄ Sample predictions:\")\n",
        "sample_results = results_df.head(10).copy()\n",
        "sample_results['TARGET_PROBA'] = sample_results['TARGET_PROBA'].round(4)\n",
        "print(sample_results)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OO7vK70waCeY",
        "outputId": "9afa9494-6468-4df6-8f99-89df6dacae13"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "üîç Quality Check:\n",
            "   - Expected features: 130\n",
            "   - Features in new data: 130\n",
            "   - Missing values after imputation: 0\n",
            "   - Data shape consistency: True\n",
            "\n",
            "üëÄ Sample predictions:\n",
            "   SK_ID_CURR  TARGET_PROBA  TARGET_PREDICTION\n",
            "0      100001        0.1825                  0\n",
            "1      100005        0.3639                  0\n",
            "2      100013        0.4263                  0\n",
            "3      100028        0.4424                  0\n",
            "4      100038        0.4151                  0\n",
            "5      100042        0.2294                  0\n",
            "6      100057        0.2895                  0\n",
            "7      100065        0.2789                  0\n",
            "8      100066        0.3013                  0\n",
            "9      100067        0.3156                  0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Executive summary\n",
        "print(\"\\n\" + \"=\"*60)\n",
        "print(\"üìã EXECUTIVE SUMMARY\")\n",
        "print(\"=\"*60)\n",
        "print(f\"Model Used: {model_package['method_used']}\")\n",
        "print(f\"Model AUC: {model_package['performance_metrics']['auc']:.4f}\")\n",
        "print(f\"Optimal Threshold: {threshold:.3f}\")\n",
        "print(f\"Total Applicants: {len(results_df):,}\")\n",
        "print(f\"Recommended for Rejection: {sum(predictions_binary):,}\")\n",
        "print(f\"Predicted Default Rate: {sum(predictions_binary)/len(predictions_binary)*100:.1f}%\")\n",
        "print(f\"Estimated Cost Savings: ${model_package['performance_metrics']['business_impact']['Cost Savings']:,}\")\n",
        "print(\"=\"*60)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9e2e32aQaGKS",
        "outputId": "4baaaf7a-0453-4a8c-c4f3-f905f5478668"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "============================================================\n",
            "üìã EXECUTIVE SUMMARY\n",
            "============================================================\n",
            "Model Used: Hyperparameter Tuned\n",
            "Model AUC: 0.7374\n",
            "Optimal Threshold: 0.699\n",
            "Total Applicants: 48,744\n",
            "Recommended for Rejection: 241\n",
            "Predicted Default Rate: 0.5%\n",
            "Estimated Cost Savings: $85,000\n",
            "============================================================\n"
          ]
        }
      ]
    }
  ]
}